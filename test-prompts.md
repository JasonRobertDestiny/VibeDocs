# MCP工具测试用例集合

## 🎯 测试目标
验证优化后的MCP工具对不同类型项目的分析和优化效果

---

## 📋 测试用例

### 1. MCP开发类项目（应该得到最高分）
```
我想开发一个MCP Server工具，集成到Claude Desktop中，帮助用户进行智能代码审查和优化建议，支持多种编程语言的静态分析。
```
**预期效果**：85-95分，触发MCP专业模板

### 2. AI Agent应用（高分项目）
```
开发一个智能客服AI助手，能够理解用户问题并提供准确回答，支持多轮对话和情感识别，可以集成到企业网站和微信公众号。
```
**预期效果**：80-85分，触发AI Agent专业模板

### 3. 简单创意想法（测试基础优化）
```
做一个记账APP
```
**预期效果**：70-75分，触发通用优化模板

### 4. 朋友圈文案生成（之前的测试案例）
```
我想开发一个朋友圈文案生成的agent，能够根据用户输入的场景、心情、事件等信息，自动生成适合发朋友圈的文案内容。
```
**预期效果**：75-80分，触发专业模板+关键词加分

### 5. 电商系统（复杂业务场景）
```
想做一个跨境电商平台，支持多币种支付，多语言界面，商品管理，订单处理，物流跟踪，用户评价系统。
```
**预期效果**：75-80分，触发电商专业模板

### 6. 数据分析工具
```
开发一个企业数据可视化平台，能够连接多种数据源，生成各类图表和报表，支持实时监控和自定义仪表板。
```
**预期效果**：78-83分，触发数据分析专业模板

### 7. 非常简单的描述（测试兜底机制）
```
想做个网站
```
**预期效果**：70-75分，应用通用优化建议

### 8. 创新科技项目
```
基于区块链技术的数字身份验证系统，结合生物识别和零知识证明，为Web3应用提供安全可靠的身份认证服务。
```
**预期效果**：75-85分，创新性高分

---

## 🔍 测试方法

1. **重启Claude Desktop**（确保加载最新MCP配置）
2. **逐个测试**以上prompt
3. **记录结果**：
   - 总体质量分数
   - 各维度分数
   - 优化建议质量
   - 是否触发专业模板

## 📊 评估标准

### 优秀表现 (85+分)
- 识别项目类型准确
- 提供专业技术建议
- 商业模式清晰
- 实施路径具体

### 良好表现 (70-84分)
- 基本识别项目需求
- 提供有用的优化建议
- 涵盖主要技术点
- 商业考虑合理

### 需要改进 (<70分)
- 建议过于通用
- 缺乏针对性
- 技术深度不够
- 商业逻辑薄弱

---

## 🎯 重点观察

1. **MCP相关项目**是否得到最高分和专业建议
2. **简单描述**是否能通过通用模板得到提升
3. **各行业项目**是否触发对应的专业模板
4. **关键词加分**机制是否正常工作
5. **整体评分**是否比之前有显著提升

测试完成后，可以对比优化前后的效果差异！
